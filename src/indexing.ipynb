{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-07T19:57:14.586743Z"
    },
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wnowogorski/Library/Caches/pypoetry/virtualenvs/chatagh-data-collecting-fbzQknWL-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "python-dotenv could not parse statement starting at line 2\n"
     ]
    }
   ],
   "source": [
    "# !pip install git+https://github.com/ChatAGH/ChatAGH_RAG#\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from src.scraper import Scraper\n",
    "from chat_agh.vector_store.mongodb import MongoDBVectorStore\n",
    "\n",
    "DATA_PATH = \"graph.json\"\n",
    "\n",
    "load_dotenv(\n",
    "    dotenv_path=\"/Users/wnowogorski/PycharmProjects/ChatAGH/DataCollecting/.env\"\n",
    ")\n",
    "\n",
    "df = pd.read_json(DATA_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6cf16e243837ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T19:54:27.767392Z",
     "start_time": "2025-10-07T19:38:35.296708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_urls = df[\"source\"].unique()\n",
    "len(unique_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165aa328f98c7a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T19:54:27.768776Z",
     "start_time": "2025-10-07T19:38:35.335403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = df[\"cluster\"].unique()\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4684f366bc8247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T19:54:27.769020Z",
     "start_time": "2025-10-07T19:45:44.520083Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_cluster(df, cluster_num):\n",
    "    output_path = f\"cluster_{cluster_num}/\"\n",
    "\n",
    "    df_subset = df[df[\"cluster\"] == cluster_num]\n",
    "    unique_urls = df_subset[\"source\"].unique()\n",
    "    unique_urls = [\"https://\" + url for url in unique_urls]\n",
    "    scraper = Scraper(urls=unique_urls[:5], output_path=output_path)\n",
    "    scraper.scrape()\n",
    "    scraper.save_result_to_json(\"docs.json\")\n",
    "\n",
    "    with open(f\"{output_path}/docs.json\", \"w\") as file:\n",
    "        docs_json = json.load(file)\n",
    "\n",
    "    documents = [\n",
    "        Document(page_content=doc[\"page_content\"], metadata=doc[\"metadata\"])\n",
    "        for doc in docs_json\n",
    "    ]\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "\n",
    "    vector_store = MongoDBVectorStore(collection_name=f\"cluster_{cluster_num}\")\n",
    "    vector_store.indexing(chunks)\n",
    "\n",
    "    failed_urls = [url.removeprefix(\"https://\") for url in scraper.failed_urls]\n",
    "    df = df[~(df[\"source\"].isin(failed_urls) | df[\"target\"].isin(failed_urls))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "id": "37f5b3916232b79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T20:01:51.343495Z",
     "start_time": "2025-10-07T20:01:43.846765Z"
    }
   },
   "source": [
    "for cluster in clusters:\n",
    "    print(\"Processing cluster: \", cluster)\n",
    "    df = process_cluster(df, cluster)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster:  3\n",
      "Processing url 1/5\n",
      "Processing url 2/5\n",
      "Processing url 3/5\n",
      "Failed to process url: Error processing HTML content: No content found on the page.\n",
      "Processing url 4/5\n",
      "Processing url 5/5\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "not readable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnsupportedOperation\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m cluster \u001B[38;5;129;01min\u001B[39;00m clusters:\n\u001B[32m      2\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mProcessing cluster: \u001B[39m\u001B[33m\"\u001B[39m, cluster)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     df = \u001B[43mprocess_cluster\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 12\u001B[39m, in \u001B[36mprocess_cluster\u001B[39m\u001B[34m(df, cluster_num)\u001B[39m\n\u001B[32m      9\u001B[39m scraper.save_result_to_json(\u001B[33m\"\u001B[39m\u001B[33mdocs.json\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/docs.json\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m     docs_json = \u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m documents = [\n\u001B[32m     15\u001B[39m     Document(page_content=doc[\u001B[33m\"\u001B[39m\u001B[33mpage_content\u001B[39m\u001B[33m\"\u001B[39m], metadata=doc[\u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs_json\n\u001B[32m     16\u001B[39m ]\n\u001B[32m     18\u001B[39m splitter = RecursiveCharacterTextSplitter(chunk_size=\u001B[32m1024\u001B[39m, chunk_overlap=\u001B[32m256\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:293\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[39m\n\u001B[32m    274\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(fp, *, \u001B[38;5;28mcls\u001B[39m=\u001B[38;5;28;01mNone\u001B[39;00m, object_hook=\u001B[38;5;28;01mNone\u001B[39;00m, parse_float=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    275\u001B[39m         parse_int=\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant=\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook=\u001B[38;5;28;01mNone\u001B[39;00m, **kw):\n\u001B[32m    276\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[32m    277\u001B[39m \u001B[33;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[32m    278\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    291\u001B[39m \u001B[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[32m    292\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m293\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m loads(\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    294\u001B[39m         \u001B[38;5;28mcls\u001B[39m=\u001B[38;5;28mcls\u001B[39m, object_hook=object_hook,\n\u001B[32m    295\u001B[39m         parse_float=parse_float, parse_int=parse_int,\n\u001B[32m    296\u001B[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001B[31mUnsupportedOperation\u001B[39m: not readable"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea77bd57db97d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
